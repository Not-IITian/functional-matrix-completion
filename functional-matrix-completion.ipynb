{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ours_neurips_submission.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF1mquekXFmO",
        "colab_type": "code",
        "outputId": "03fd4619-c903-4261-9064-7c79d08cc15d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import matplotlib\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "random.seed(0)\n",
        "np.random.seed(0) \n",
        "\n",
        "import h5py\n",
        "import scipy.io as sio\n",
        "import scipy.sparse as sp\n",
        "from scipy.sparse.linalg import eigs\n",
        "from scipy import linalg as linalg\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "from numpy import linalg as npla\n",
        "from numpy import matlib\n",
        "import IPython\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ia_sXkjfRFfL",
        "colab_type": "text"
      },
      "source": [
        "This is the code to replicate results submitted in the paper. Please download the matlab files containing user and movies graph from prior work such as Monti et. al or Boyarski et. al. Please upload these matrices to your google drive so that google colab can access it.\n",
        "\n",
        "In code below, for Flixter dataset, we set m and n  to 2990. For Movie Lens 100k, we set m and n to 900 and 1650. Note that the values of p_max and q_max are set to the dimensions of underlying rating matrix. For Synthetic netflix, we set m and n to 30. For synthetic Netflix, we obtain best results with perturbation in underlying graphs i.e. random deletion of edges from the graph helps to improve the performance. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rimXetCXHC7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_matlab_file(path_file, name_field):\n",
        "    \n",
        "    db = h5py.File(path_file, 'r')\n",
        "    ds = db[name_field]\n",
        "    try:\n",
        "        if 'ir' in ds.keys():\n",
        "            data = np.asarray(ds['data'])\n",
        "            ir = np.asarray(ds['ir'])\n",
        "            jc = np.asarray(ds['jc'])\n",
        "            out = sp.csc_matrix((data, ir, jc)).astype(np.float32)\n",
        "    except AttributeError:\n",
        "        # Transpose in case is a dense matrix because of the row- vs column- major ordering between python and matlab\n",
        "        out = np.asarray(ds).astype(np.float32).T\n",
        "    db.close()\n",
        "    return out\n",
        "\n",
        "def eigen(A):\n",
        "    eigenValues, eigenVectors = npla.eigh(A)\n",
        "    idx = np.argsort(eigenValues)\n",
        "    eigenValues = eigenValues[idx]\n",
        "    eigenVectors = eigenVectors[:, idx]\n",
        "    return (eigenValues, eigenVectors)\n",
        "\n",
        "def init_graph_basis(W):\n",
        "    # gets basis returns eig_vals and eig_vecs\n",
        "    W = W - np.diag(np.diag(W))\n",
        "    D = np.diagflat(np.sum(W, 1))\n",
        "    L = D - W\n",
        "    eig_vals, eig_vecs = eigen(L)\n",
        "    return eig_vals, eig_vecs\n",
        "\n",
        "\n",
        "def squared_frobenius_norm(tensor):\n",
        "    square_tensor = tf.square(tensor)\n",
        "    tensor_sum = tf.reduce_sum(square_tensor)\n",
        "    return tensor_sum"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gReP8hjyZbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load graphs and compute eigendecomposition of Laplacians\n",
        "\n",
        "path_dataset = '/content/drive/My Drive/Colab Notebooks/training_test_dataset_10_NNs.mat' # flixter\n",
        "\n",
        "#path_dataset = '/content/drive/My Drive/Colab Notebooks/split_1.mat'\n",
        "#path_dataset = '/content/drive/My Drive/Colab Notebooks/synthetic_netflix.mat'\n",
        "W_rows = load_matlab_file(path_dataset, 'W_users')\n",
        "#.todense()  # Row Graph\n",
        "W_cols = load_matlab_file(path_dataset, 'W_movies')\n",
        "#.todense()  # Column Graph\n",
        "#W_rows = load_matlab_file(path_dataset, 'Wrow').todense()  # Row Graph for syntheitc netflix\n",
        "#W_cols = load_matlab_file(path_dataset, 'Wcol').todense()  # Column Graph for syntheitc netflix\n",
        "m = 2990  # this is for flixter\n",
        "n = 2990\n",
        "\n",
        "\n",
        "# extract Laplacians of the row and column graphs\n",
        "eig_vals_row, eig_vecs_row = init_graph_basis(W_rows)\n",
        "eig_vals_col, eig_vecs_col = init_graph_basis(W_cols)\n",
        "\n",
        "M = load_matlab_file(path_dataset, 'M')\n",
        "S_training = load_matlab_file(path_dataset, 'Otraining')\n",
        "S_test = load_matlab_file(path_dataset, 'Otest')\n",
        "M_training = np.array(M)*np.array(S_training)\n",
        "M_test = np.array(M)*np.array(S_test)\n",
        "\n",
        "lr = 0.000001 \n",
        "num_iters = 12000\n",
        "p_init = 1\n",
        "q_init = 1\n",
        "p_max = 3000\n",
        "q_max = 3000 #flixter\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qStnYdQu0KMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "C_init = np.zeros([p_max, q_max], dtype = np.float32)\n",
        "#C_init = np.zeros([m, n], dtype = np.float32)\n",
        "C_init[p_init-1,q_init-1] = np.matmul(np.matmul(np.transpose(eig_vecs_row[:, 0:p_init]),M_training), eig_vecs_col[:, 0:q_init])\n",
        "\n",
        "P_init = np.eye(m, p_max)\n",
        "Q_init = np.eye(n, q_max)\n",
        "\n",
        "C_tf = tf.Variable(C_init, trainable=True, dtype=tf.float32)\n",
        "#C_tf = tf.Variable(np.matmul(np.matmul(P_init, C_init), np.transpose(Q_init)), trainable=True, dtype=tf.float32)\n",
        "P_tf = tf.Variable(P_init, trainable=True, dtype=tf.float32)\n",
        "Q_tf = tf.Variable(Q_init, trainable=True, dtype=tf.float32)\n",
        "C_new = tf.matmul(tf.matmul(P_tf, C_tf), tf.transpose(Q_tf)) #check\n",
        "#C_new = C_tf\n",
        "Phi_tf = tf.constant(eig_vecs_row[:,0:m], dtype=tf.float32)\n",
        "Psi_tf = tf.constant(eig_vecs_col[:,0:n], dtype=tf.float32)\n",
        "\n",
        "lambda_row_tf = tf.constant(eig_vals_row[0:m], dtype=tf.float32)\n",
        "lambda_col_tf = tf.constant(eig_vals_col[0:n], dtype=tf.float32)\n",
        "\n",
        "S_training_tf = tf.constant(S_training, dtype=tf.float32)\n",
        "S_test_tf = tf.constant(S_test, dtype=tf.float32)\n",
        "M_training_tf = tf.constant(M_training, dtype=tf.float32)\n",
        "M_test_tf = tf.constant(M_test, dtype=tf.float32)\n",
        "X = tf.matmul(tf.matmul(Phi_tf, C_new), tf.transpose(Psi_tf))\n",
        "\n",
        "E_data = squared_frobenius_norm(tf.multiply(X, S_training) - M_training)\n",
        "\n",
        "C_new_t = tf.transpose(C_new)\n",
        "left_mul = tf.matmul(C_new, tf.diag(lambda_col_tf))\n",
        "right_mul = tf.matmul(tf.diag(lambda_row_tf),C_new)\n",
        "E_comm = squared_frobenius_norm(left_mul-right_mul)\n",
        "\n",
        "E_tot = E_data + .00001*E_comm\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr)\n",
        "opt_op = optimizer.minimize(E_tot)\n",
        "# Create a session for running Ops on the Graph.\n",
        "config = tf.ConfigProto(allow_soft_placement=True)\n",
        "config.gpu_options.allow_growth = True\n",
        "sess = tf.Session(config=config)\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "train_loss = tf.sqrt(squared_frobenius_norm(tf.multiply(X, S_training_tf) - M_training_tf)/ tf.reduce_sum(S_training_tf))\n",
        "#validation_loss = tf.sqrt(squared_frobenius_norm(tf.multiply(S_validation_tf, (X - M))) / tf.reduce_sum(S_validation_tf))\n",
        "test_loss = tf.sqrt(squared_frobenius_norm(tf.multiply(X, S_test_tf)- M_test_tf)/tf.reduce_sum(S_test_tf))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYWrcxcUa3Uw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for iter in range(12000):\n",
        "    if iter%100 == 0:\n",
        "      train_loss_np, test_loss_np = sess.run([train_loss, test_loss])\n",
        "      IPython.display.clear_output()    \n",
        "      print(\"iter \" + str(iter) +\" ,train loss: \"+str(train_loss_np)+\", test loss: \" + str(test_loss_np) )\n",
        "      #X_np = sess.run(X)      \n",
        "      #plt.imshow(X_np)\n",
        "      #plt.title('X')\n",
        "      #plt.show()\n",
        "    sess.run(opt_op)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}